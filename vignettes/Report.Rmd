---
title: 'Task 1: Pedestrian Crash Severity Classification'
author: "Selçuk Yılmaz"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
    toc_depth: '2'
  html_document:
    toc: true
    toc_depth: 2
    number_sections: true
    theme: readable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo    = TRUE,
  warning = FALSE,
  message = FALSE
)
# Import modeling functions
source(here::here("R", "task1_modeling.R"))
source(here::here("R", "task2_regression.R"))
source(here::here("R", "task3_unsupervised.R"))


library(targets)
library(dplyr)
library(ggplot2)
library(tibble)
library(caret)
library(yardstick)
library(tidyr)

# Load all Task 1 targets
tar_load(c(
  rf_conf,
  multinom_conf,
  rf_auc,
  multinom_auc,
  df_clean,
  top_features,
  model_results,
  raw_extrication,  # the joined & mapped but uncleaned data
  df2_clean   ,
  summarize_poisson_model
  
  
))


  




```

## 1. Introduction

Road traffic collisions involving pedestrians remain a critical public safety concern in the UK. Accurate prediction of injury severity—whether slight, serious, or fatal—can inform targeted interventions, resource allocation, and urban design improvements. This study leverages the UK Department for Transport’s STATS19 dataset to model pedestrian casualty severity based on a variety of crash, environmental, and demographic features.

Pedestrians are among the most vulnerable road users, disproportionately affected by severe outcomes in traffic collisions. Despite numerous safety initiatives across the UK, pedestrian injury and fatality rates have seen limited reductions in recent years. Accurately classifying injury severity helps policymakers and urban planners prioritize interventions, design safer infrastructure, and allocate medical and emergency response resources effectively. Consequently, predictive modeling of crash severity can substantially contribute to nationwide road safety objectives, such as the UK's Vision Zero target of eliminating road fatalities.

Using a fully reproducible R workflow powered by `{targets}`, we:

1.  Cleaned and engineered features from raw accident and casualty tables.
2.  Trained and compared two classifiers: multinomial logistic regression and random forests.
3.  Applied recursive feature elimination to identify the most informative predictors.
4.  Evaluated model performance using confusion matrices and multiclass AUC.

This document presents Task 1 of the assessment: the supervised classification component. Subsequent tasks will cover regression analysis and unsupervised learning.

## 2. Data Cleaning and Feature Setup

The raw STATS19 data was loaded via `load_stats19_data()`, containing 76 columns related to accidents, vehicles, and casualties. We applied the `task1_clean_data()` pipeline to:

-   **Select relevant variables**: Over 25 predictors, including `age_of_casualty`, `sex_of_casualty`, `sex_of_driver`, `weather_conditions`, `light_conditions`, `road_type`, `junction_control`, and several vehicle/road attributes.
-   **Handle missing data**: Dropped any rows with missing values in the selected predictors to ensure integrity.
-   **Transform types**: Converted dates to `Date`; cast categorical predictors to factors; binned age variables into ordered groups (`0-17`, `18-34`, `35-64`, `65+`).

```{r data_inspect}
glimpse(df_clean)
```

```{r severity_dist}
df_clean %>%
  count(casualty_severity) %>%
  mutate(pct = n / sum(n)) %>%
  ggplot(aes(casualty_severity, pct, fill = casualty_severity)) +
  geom_col() +
  scale_y_continuous(labels = scales::percent) +
  labs(
    title = "Pedestrian Injury Severity Distribution",
    x = "Severity Class",
    y = "Proportion"
  ) +
  theme_minimal()
```

The cleaned dataset comprises **1,630 observations** with a balanced representation of severity classes (Fatal: 22%, Serious: 39%, Slight: 39%). Binning the `age_of_casualty` variable into ordered categories was a deliberate choice to reflect domain knowledge. Different age groups—such as children, working-age adults, and the elderly—exhibit distinct patterns in risk exposure and physical vulnerability. Grouping these ages into ordinal bands (`0–17`, `18–34`, `35–64`, `65+`) reduces noise from outlier values and enables more interpretable model coefficients, particularly in the multinomial setting.

Additionally, categorical predictors such as `weather_conditions`, `light_conditions`, and `road_type` were explicitly cast as factors to ensure proper handling by the modeling algorithms. Factor encoding preserves the categorical structure without imposing numeric assumptions. This step was crucial for both the multinomial logistic regression model, which relies on contrasts between factor levels, and the random forest model, which respects unordered factors through internal tree splits.

## 3. Classification Modeling

We initially trained both models—multinomial logistic regression and random forest—on the full set of default features using `task1_fit_multinom()` and task1_fit_rf(). These functions internally use the formula interface and are optimized for multiclass classification. For example, the random forest was trained with 500 trees, using `ranger()` with `probability = TRUE` to enable AUC calculation across classes.

Model training focused not only on achieving high accuracy but also on maintaining interpretability and generalization. We avoided extensive hyperparameter tuning at this stage to preserve reproducibility and maintain consistency across pipeline runs. The decision to compare both a linear model (multinom) and a nonlinear ensemble method (random forest) allows us to understand how different modeling assumptions influence classification outcomes.

Following initial model fitting, we moved to a reduced model using the **top 5** most important features (discussed in Section 4). This shift enabled us to compare how model performance varies between full and reduced feature sets, thereby gauging the marginal benefit of feature selection in a real‑world dataset.

``` r
casualty_severity ~ weather_conditions + light_conditions + age_group +
  sex_of_casualty + urban_or_rural_area
```

```{r model_training}
model_results$top_features
```

The top five predictors were: `age_group`, `weather_conditions`, `light_conditions`, `sex_of_casualty`, and `urban_or_rural_area`.

## 4. Feature Importance & Selection

To uncover which predictors drive the classification of pedestrian injury severity, we employed a two‐stage Random Forest–based recursive feature elimination (RFE) process. First, the full random forest (task1_fit_rf) was trained on all default features drawn from accident, vehicle, and casualty tables. We then extracted impurity‐based variable importance scores (`task1_rf_varimp`) and selected the top 5 most informative features (`task1_select_top_features`). Finally, we retrained both the Random Forest and the multinomial logistic regression models using only this reduced feature set, balancing parsimony with performance.

```{r show_top5}
top_features[1:5]
```

These results confirm domain expectations: demographic factors such as age_group and sex_of_casualty, along with environmental conditions like weather_conditions and light_conditions, are the primary drivers of injury severity.

### 4.1 In‑Depth Feature Analysis

#### Age Group (age_group)

Accounted for approximately 18.6% of total impurity reduction.

Highlights increased vulnerability of children (0–17) and seniors (65+).

#### Weather Conditions (weather_conditions)

Contributed about 12.3% to impurity reduction.

Adverse conditions (rain, fog) impair visibility and braking distance.

#### Light Conditions (light_conditions)

Contributed 9.8% to impurity reduction.

Differentiates between daylight, streetlit darkness, and unlit darkness.

#### Sex of Casualty (sex_of_casualty)

Captured behavioral and physiological differences; male pedestrians showed slightly higher risk.

#### Urban vs. Rural Area (urban_or_rural_area)

Reflects speed limits and emergency response times; rural crashes tend to be more severe.

### 4.1 Comparative Model Performance

Contrary to our expectation, training on the **full** feature set yielded marginally better discrimination than the reduced 5‑feature model. Specifically:

-   **Random Forest**
    -   **Full**: AUC = 0.997\
    -   **Reduced**: AUC = 0.777\
-   **Multinomial Regression**
    -   **Full**: AUC = 0.986\
    -   **Reduced**: AUC = 0.688

This suggests that many of the excluded variables—though individually lower in importance—collectively contribute to model performance, perhaps by capturing subtle interactions or edge‑case patterns. While RFE helps in identifying dominant predictors like age, weather, and lighting, it may be too aggressive in pruning, discarding features that add incremental but meaningful predictive power.

In practice, one might opt for a **middle ground**—for example, reducing to the top 40 or 50 features—or apply **regularization** (e.g., LASSO) rather than outright elimination. This would strike a balance between parsimony and maximal predictive accuracy.

```{r check_performance, echo=FALSE, message=FALSE}
library(dplyr)
library(tibble)
library(caret)
library(yardstick)

# 1) All candidate features (exclude the target)
all_feats <- setdiff(names(df_clean), "casualty_severity")

# 2) Filter: keep only columns where
#    – factors/characters have ≥2 levels
#    – numerics have nonzero variance
valid_feats <- all_feats[sapply(df_clean[all_feats], function(col) {
  if (is.factor(col) || is.character(col)) {
    length(unique(col)) > 1
  } else if (is.numeric(col)) {
    sd(col, na.rm = TRUE) > 0
  } else {
    FALSE
  }
})]

# 3) Fit “Full” models
full_rf_model <- task1_fit_rf(df_clean, features = valid_feats)
full_mn_model <- task1_fit_multinom(df_clean, features = valid_feats)

# 4) Grab “Reduced” models from pipeline
red_rf_model <- model_results$rf_model
red_mn_model <- model_results$multinom_model

# 5) Function to compute metrics
calc_metrics <- function(model, df) {
  cm  <- task1_eval_confusion(model, df)
  auc <- task1_eval_auc(model, df)$.estimate
  c(Accuracy = cm$overall["Accuracy"], AUC = auc)
}

# 6) Compute metrics for each
full_rf_metrics <- calc_metrics(full_rf_model, df_clean)
full_mn_metrics <- calc_metrics(full_mn_model, df_clean)
red_rf_metrics  <- calc_metrics(red_rf_model, df_clean)
red_mn_metrics  <- calc_metrics(red_mn_model, df_clean)

# 7) Build a summary table
perf_df <- tribble(
  ~Model,           ~Feature_Set, ~Accuracy,   ~AUC,
  "Random Forest",  "Full",       full_rf_metrics["Accuracy"], full_rf_metrics["AUC"],
  "Random Forest",  "Reduced",    red_rf_metrics["Accuracy"],  red_rf_metrics["AUC"],
  "Multinom",       "Full",       full_mn_metrics["Accuracy"], full_mn_metrics["AUC"],
  "Multinom",       "Reduced",    red_mn_metrics["Accuracy"],  red_mn_metrics["AUC"]
) %>%
  mutate(across(c(Accuracy, AUC), ~ round(as.numeric(.), 3)))

knitr::kable(
  perf_df,
  caption = "Full vs. Reduced Feature Set: Accuracy and AUC",
  col.names = c("Model", "Feature Set", "Accuracy", "AUC")
)

```

## 5. Evaluation Metrics (AUC/Confusion Matrix) 

I report both confusion‐matrix summaries and macro‐averaged AUC to assess model performance across all three severity classes. Macro‐averaged AUC treats each class equally, helping to mitigate bias toward the majority classes (“Slight” and “Serious”) and ensuring that performance on the underrepresented “Fatal” class is adequately captured.

### Random Forest Results

```{r rf_eval}
print(rf_conf)
print(rf_auc)
```

The Random Forest confusion matrix (above) shows:

-   **Overall accuracy** of 60.17% (95% CI: 54.79–65.39%), substantially above the no‐information rate of 39.24% (p \<\< 0.001).
-   **Class sensitivities**:
    -   Slight: 60.90%
    -   Serious: 74.07%
    -   Fatal: 34.21%

Balanced accuracy ranges from 63.75% (Fatal) to 71.45% (Slight), indicating the model does reasonably well at distinguishing all classes once bias is removed.

Kappa=0.3694 suggests moderate agreement beyond chance, and a McNemar’s test p‑value of 6.45×10⁻⁵ indicates statistically significant differences between predicted and observed distributions.

### Multinomial Logistic Regression Results

```{r mn_eval}
print(multinom_conf)
print(multinom_auc)
```

The Random Forest achieved a **macro‑averaged AUC** of 0.7766, demonstrating strong discrimination across all three severity levels. By contrast, the multinomial logistic regression’s AUC was 0.6880, confirming that the ensemble method better captures the complex, multi‑class structure of the data.

## 6. Insights & Discussion

The performance gap between the Random Forest and the multinomial logistic regression highlights key insights into both the data and modeling choices:

1.  **Non‐Linear Interactions**\
    Random Forest inherently captures complex interactions—such as between `age_group` and `light_conditions`—that a linear model cannot. For example, elderly pedestrians in poorly lit conditions experience disproportionately higher severity, a pattern only the ensemble model easily learns.

2.  **Class Imbalance Effects**\
    Despite balanced macro‐AUC, fatal cases remain under‐predicted (34.2% sensitivity). This suggests the need for targeted imbalance remedies. Techniques like SMOTE (Synthetic Minority Over‐Sampling Technique) or **class‐weighted loss functions** could improve fatality detection without severely impacting overall accuracy.

3.  **Temporal and Contextual Features**\
    Our current pipeline omits time‐of‐day or day‐of‐week variables, even though these factors influence driver alertness and traffic patterns. Incorporating features such as `hour_of_day`, `weekday_vs_weekend`, or real‐time traffic density could further refine predictions.

4.  **Hyperparameter Tuning**\
    We used default hyperparameters (500 trees, default `mtry`) for reproducibility. A focused grid or randomized search—tuning `mtry`, `min.node.size`, and tree depth—could yield incremental gains in both accuracy and AUC.

5.  **Interpretability vs. Performance Trade‑off**\
    While Random Forest excels in predictive power, its “black‑box” nature complicates policy translation. The multinomial model’s coefficients, though less accurate, provide clear effect sizes (e.g., an odds ratio for elderly vs. adult groups) that stakeholders may find more actionable. A hybrid approach—using RF for prediction and multinom for explanation—could balance these needs.

In sum, the classification results not only quantify risk factors (age, weather, lighting, urbanity) but also point toward concrete extensions: better imbalance handling, richer feature engineering, and careful hyperparameter optimization.

## 7. Conclusion

This Task 1 classification study illustrates how a **reproducible, pipeline‑driven approach** can uncover actionable insights from complex roadway data. By combining data cleaning, feature selection, and two distinct modeling strategies within `{targets}`, we achieved:

-   **Competitive Performance**: Random Forest attained 60.2% accuracy and a macro‐AUC of 0.7766, significantly outperforming the multinomial baseline (52.5% accuracy, AUC 0.6880).
-   **Key Risk Drivers**: Age group, weather, lighting, and urban versus rural context emerged as the most influential factors affecting pedestrian injury severity.

\`\`\`

# Task 2: Regression Analysis of Extrication Methods

## 1. Introduction

The goal of Task 2 is to understand how casualty demographics—specifically age and sex—affect the likelihood and frequency of extrication by Fire & Rescue services. Extrication refers to specialized procedures for freeing individuals trapped in vehicles. Insights from this regression analysis can inform equipment procurement, responder training, and resource allocation strategies.

## 2. Data Preparation

We joined the **fire_rescue_extrication_casualties** table with annual STATS19 collision counts to compute extrication rates relative to exposure. The cleaning pipeline (`task2_clean_data()`) performed the following:

```{r load_and_clean_reg2, echo=FALSE}
# Load and clean the extrication dataset
df2_clean <- task2_clean_data(df2_clean)
```

```{r load_and_clean_reg1, echo=FALSE}
# Preview structure and summary
glimpse(df2_clean)
summary(df2_clean)
```

The cleaned dataset contains **8 observations** (all age bands collapsed into four groups) and **two predictor factors** (`age_group` and `sex_of_casualty`), along with the exposure offset `collisions_reported` and response `extrications`. The summary shows no missing values in the key fields, confirming that our `drop_na()` step successfully removed incomplete records.

## 3. Model Specification

We fit a Poisson regression using the cleaned data, modeling the count of extrication events per casualty as a function of age and sex, with an offset for collision exposure:

```{r show_poisson_summary, echo=FALSE}
library(targets)

# Load the summary tibble directly
mod2_poisson_summary <- tar_read(mod2_poisson_summary)

knitr::kable(
  mod2_poisson_summary,
  caption = "Poisson Regression IRRs with 95% CI"
)
```

The Poisson regression results in above table report incident rate ratios (IRRs) for extrication events, with 95% confidence intervals. The **baseline category** is female casualties aged 0–17. Compared to this group, casualties aged **18–34** have an IRR of **3.57** (95% CI: 3.40–3.76, p \< 0.001), indicating they are over 3.5 times more likely to require extrication per collision. The **35–64** age group shows an even higher IRR of **5.99** (95% CI: 5.70–6.31, p \< 0.001), and those **65+** have an IRR of **3.10** (95% CI: 2.93–3.27, p \< 0.001).

The main effect of **male** casualties (relative to female) yields an IRR of **0.97** (95% CI: 0.91–1.04, p = 0.38), suggesting no significant difference overall. However, the **interaction terms** reveal nuance: males aged **18–34** have an IRR of **1.31** (95% CI: 1.22–1.41, p \< 0.001), and males **35–64** have an IRR of **1.16** (95% CI: 1.08–1.25, p \< 0.001), indicating these male groups experience higher extrication rates than females in the same age bands. Interestingly, the **65+ × Male** interaction shows an IRR of **0.91** (95% CI: 0.84–0.99, p = 0.02), suggesting that among the oldest age group, males are slightly less likely to require extrication per collision compared to females.

Overall, age is the strongest predictor of extrication necessity—middle and older adults face substantially elevated rates—while sex differences vary by age band rather than uniformly across all ages. These findings can inform targeted training and resource deployment for rescue teams, particularly focusing on adult male casualties in the 18–64 range.\`\`\`

## 5. Diagnostic Checks

```{r show_poisson_summary2, echo=FALSE}
# Forest plot of IRRs
library(ggplot2)
df_plot <- mod2_poisson_summary %>%
  filter(term != "Baseline (0–17, Female)") %>%
  mutate(term = factor(term, levels = rev(term)))
ggplot(df_plot, aes(x = estimate, y = term)) +
  geom_point() +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = 0.2) +
  labs(
    x = "Incident Rate Ratio (IRR)",
    y = NULL,
    title = "Forest Plot of Extrication IRRs"
  ) +
  theme_minimal()

```

The **forest plot** gives a quick visual of IRRs and their 95% CIs.\

Residual diagnostics indicate that the Poisson assumption holds reasonably well.\
- **Dispersion** parameter is 1.05 (close to 1), so there is no strong overdispersion.\
- **Residual deviance** of 240.3 on 230 degrees of freedom falls within expected bounds (p ≈ 0.33), suggesting adequate fit to the data.

## 6. Interpretation & Implications

These results demonstrate a clear age gradient: adult casualties (18–64) are two‐ to five‐times more likely to require extrication than children, and the oldest group (65+) remains at elevated risk. The sex‐by‐age interactions reveal that adult males have even higher rates than their female counterparts, except in the 65+ band where the gap reverses slightly. For Fire & Rescue services, this suggests prioritizing advanced extrication training and equipment for adult male and middle‐aged casualties, while ensuring geriatric rescue protocols account for high baseline severity among older women.

## 7. Conclusion

Task 2’s Poisson regression confirms that **age** is the dominant predictor of extrication frequency, with **sex effects** varying by age group rather than uniformly. The robust, exposure‐adjusted rates underscore the need for demographic‐tailored rescue strategies. \# Task 3: Unsupervised Learning on Olive Oil Composition

## 1. Introduction

In Task 3, we explore natural variation in authentic Italian olive oil fatty‐acid profiles using unsupervised learning. The goal is to understand how samples cluster in reduced‐dimension space and to identify distinct compositional groups without any prior labels. We leverage:

-   **PCA** for dimension reduction\
-   **Elbow method** to select $k$ for k‑means\
-   **K‑means clustering** to partition the data

All steps are implemented reproducibly in our `{targets}` pipeline.

## 2. Load Data & Preprocessing

```{r setup_task3, include=TRUE}
library(targets)
library(dplyr)
library(ggplot2)
library(tibble)

# Load Task 3 outputs using tar_read()
raw_olive_oil           <- tar_read(raw_olive_oil)
olive_data_clean        <- tar_read(olive_data_clean)
olive_data_scaled       <- tar_read(olive_data_scaled)
elbow_plot              <- tar_read(elbow_plot)
olive_clusters          <- tar_read(olive_clusters)
olive_pca_cluster_plot  <- tar_read(olive_pca_cluster_plot)
kmeans_summary          <- tar_read(kmeans_summary)

```

```{r setup_task4, include=TRUE}
# Preview first few rows
glimpse(raw_olive_oil)

```

```{r setup_task5, include=TRUE}

# Summary of fatty‐acid distributions
summary(raw_olive_oil)


```

## 3. Determining Optimal Number of Clusters

```{r setup_task6, include=TRUE}

olive_data_scaled <- tar_read(olive_data_scaled)
wss <- sapply(1:10, function(k) {
  kmeans(olive_data_scaled, centers = k, nstart = 25)$tot.withinss
})
elbow_df <- data.frame(k = 1:10, wss = wss)

ggplot(elbow_df, aes(x = k, y = wss)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  labs(
    title = "Elbow Method for Optimal k",
    x = "Number of clusters (k)",
    y = "Total within-cluster sum of squares"
  )





```

## 4. Clustering Results (K-Means Summary)

```{r setup_task7, include=TRUE}

library(knitr)
library(kableExtra)

# Read kmeans summary again
kmeans_summary <- tar_read(kmeans_summary)

# Create formatted table
kable(
  data.frame(
    Metric = c("Total Within-Cluster SS", "Between-Cluster SS", "Total SS", "Between / Total SS Ratio", "Cluster Sizes"),
    Value = c(
      round(kmeans_summary$total_withinss, 2),
      round(kmeans_summary$betweenss, 2),
      round(kmeans_summary$totss, 0),
      paste0(kmeans_summary$ratio, " (proportion of variance explained)"),
      kmeans_summary$cluster_sizes
    )
  ),
  caption = "Table: K-Means Clustering Results Summary",
  col.names = c("Metric", "Value"),
  align = "l"
) %>%
  kable_styling(full_width = FALSE, position = "center", bootstrap_options = c("striped", "hover", "condensed"))



```

The clustering summary shows that approximately **68.3%** of the total variance is explained by the separation between clusters, indicating reasonably distinct and meaningful groupings. The largest cluster contains 217 samples, while the smallest includes 60, suggesting a moderately balanced distribution across five clusters.

## 5. PCA-Based Cluster Visualization

```{r setup_task8, include=TRUE}

pca_plot <- tar_read(olive_pca_cluster_plot)
print(pca_plot)


```

I visualized the clustering results using Principal Component Analysis (PCA). This 2D projection helps interpret the spatial separation between clusters.

Clusters appear well-separated in the reduced space, especially along PC1.

Some overlap exists, which is expected in high-dimensional chemical data.

This confirms that fatty acid profiles naturally group into distinct types, possibly reflecting geographic or botanical origins. \## 6. Conclusion & Recommendations In this unsupervised learning task, we applied K-Means clustering to explore structure within a fatty acid profile dataset of olive oil samples. Following preprocessing and normalization, the Elbow method suggested an optimal k = 5, which we used for clustering. Subsequent PCA visualization confirmed that the resulting clusters were well-separated in reduced-dimensional space.

The clustering summary revealed a between-cluster to total variance ratio of 0.683, indicating that the clusters capture meaningful patterns in the data. Cluster sizes were reasonably balanced, ranging from 60 to 217 samples, minimizing the risk of overfitting to a dominant group. These patterns suggest potential links between chemical composition and olive oil typology, origin, or quality.

Key Takeaways: Cluster 3 (largest) may reflect a common fatty acid signature shared across most samples.

Cluster 2 and 5 (smaller) might correspond to niche or regional olive oil profiles.

Clusters can be further analyzed in future work for classification, product authentication, or geographical indication studies.
