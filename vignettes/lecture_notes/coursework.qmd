---
title: "MTHM053 Applications of Data Science and Statistics – Coursework Brief"
author: "Paul Hewson, University of Exeter"
date: "2025-06-03"
format: html
self-contained: true
---

# Overview

This coursework assesses your ability to build, validate, and communicate a set of applied data science models using R. You will complete three core analytical tasks — supervised classification, regression modelling, and unsupervised learning — all within a fully **reproducible pipeline** built using modern tools

## Objectives

By completing this coursework, you will demonstrate:

- Supervised learning skills (classification, regression, model selection)

- Unsupervised learning skills (dimension reduction and clustering)

- Reproducible workflow design using `renv`, `targets`, `git`, and `testthat`

- Clear and structured scientific communication via PDF report

---

# Project Tasks

## 1. Supervised Classification Task

Predict the **severity** of a pedestrian-involved crash (*fatal*, *serious*, *slight*) based on crash characteristics such as:

- Time and date

- Weather and lighting

- Casualty and driver age/sex

- Urban/rural location

**You must:**

- Obtain data on pedestrian casualties from the `supabase` database in the `stats19_casualties` table. You can combine with information on the collisions (in the `stats19_accidents` table) and the involved vehicles (in the `stats19_vehicles` table). You can use SQL or R pipelines as you prefer to prepare the data

- Train and compare at least two models

- Evaluate performance using appropriate metrics (e.g., accuracy, AUC)

---

## 2. Regression Task

Analyse the effect of **casualty age and sex** on the **method of extrication** used by the fire brigade. "Extrication" refers to a procedure whereby the Fire and Rescue Service use specialised equipment, which involves cutting apart a car, in order to free a casualty who is trapped inside a car.

**You must:**

- Obtain the fire and rescue data from `supabase` database in the `fire_rescue_extrications_casualties` table. If you wish to know the extrications as a rate, given the number of police reported collisions you can obtain numbers of police reported collisions in the `stats19_by_financial_year`

- Build a suitable regression model (e.g., generalised linear model, generalised additive model)

- Explore potential interactions

- Report and interpret coefficients

---

## 3. Unsupervised Learning Task

Adulteration of olive oil with cheaper oils is a growing commercial problem. "Adulteration" refers to the process whereby an expensive product (in this case Olive oil) is mixed with a cheaper product (in this case some other oil) in the hope of fooling a customer into thinking they have bought a pure version of the more expensive product. As a prelude to developing methods to identify adulterated olive oil, a client wishes to understand more about the natural variation in olive oil composition. The `supabase` table `olive_oil` contains the composition of eight fatty acids in a sample of 572 Italian Olive oils that are known not to be adulterated.

**You must:**

- Before and after your analysis use appropriate exploratory data analysis techniques

- Apply a dimension reduction technique and at least one clustering method (e.g., k-means, DBSCAN)

- Justify scaling choices

- Evaluate clustering quality and provide an interpretation of your findings

---

## 4. Reproducibility and Workflow Management

You must:

- Fork the provided [GitHub template repository](https://github.com/phewson/mthm503)

- Share your fork with the module leader [phewson](https://github.com/phewson) before the submission deadline

- Maintain your work in a `targets` pipeline

- Manage dependencies using `renv`

- Include at least **two unit tests** that you have written using `testthat`

- Ensure code passes the built-in `lintr` GitHub Action without excessive use of `# nolint`

---

# Use of GenAI tools in MTHM503 Applications of Data Science and Statistics

The University of Exeter is committed to the ethical and responsible use of Generative Artificial Intelligence (GenAI) tools in teaching and learning, in line with our academic integrity policies. Direct copying of AI-generated content can be an academic offence and is addressed under plagiarism, misrepresentation and contract cheating in section 12.3 of the Teaching Quality Assurance manual. To support students with assessments, staff will identify whether the use of GenAI tools is integrated, supported or prohibited in each assessment. Further guidance on using GenAI tools to enhance your learning, and on referencing them appropriately, is available on Study Zone digital.

This assessment is AI-supported. This is because some uses of GenAI tools may help you to complete the assessment without compromising your ability to demonstrate that you have achieved the intended learning outcomes. See overleaf for guidance about appropriate uses of GenAI tools.

When submitting your assessment, you must include the declaration below, listing all the ways in which you have used GenAI tools for this assessment. You must also reference the use of GenAI outputs within your assessment, in line with the University’s referencing guidelines. You should also keep a record of which GenAI tools you use, including the prompts and outputs, in case you are asked to present this at a viva.

Submitting your work without an accompanying declaration, or one with no uses listed, will be considered a declaration that you have not used GenAI tools in preparing your work. If a declaration cannot be uploaded then by submitting your assessment you are confirming that you have followed the instructions for the assessment and the guidelines about using GenAI tools.

## Student declaration

This assessment is AI-supported. I acknowledge the following uses of GenAI tools in this assessment.

- [ ] I have used GenAI tools to suggest section headings for my report.

- [ ] I have used GenAI tools to help me to correct my grammar or spelling.

- [ ] I have used GenAI tools to suggest topics to discuss in my literature review.

- [ ] I declare that I have referenced the use of GenAI outputs within my assessment, in line with the University’s referencing guidelines.

## How may I use GenAI tools for my assessment?

Any work that you submit for formative or summative assessment must be your own. This means that you must produce the work yourself and it must reflect your own knowledge, understanding and capabilities. The following paragraphs explain how you may use GenAI tools while still ensuring that the work you submit is your own. If you are unsure what uses of GenAI tools are appropriate for an assessment then please ask the module leader.

AI-supported assessments. Here are two examples which illustrate appropriate uses of GenAI tools for AI-supported assessments.

1.	If you use an AI to write part of a report and copy the text without referencing it then this would be an academic offence. If you quote the text and reference it correctly then this would not be an academic offence but it would not be your own work and so you would receive no credit for it. If you use an AI to suggest some ideas which you incorporate into your report, and you acknowledge the source of these ideas and write the report yourself, then this would be your own work and you would receive full credit.

2. If you use an AI to do a calculation and copy the calculation without referencing it then this would be an academic offence. If you quote the calculation and reference it then this would not be an academic offence but it would not be your own work and so you would receive no credit for it. If you use an AI to suggest a method which you use for the calculation, and you acknowledge the source of this method and do the calculation yourself, then this would be your own work and you would receive full credit.

The formula is similar for other types of work: you may use an AI to suggest some mathematical models but you must declare this use and select a model yourself; you may use an AI to suggest how to structure or how to correct computer code but you must declare this use and write the code yourself; you may use an AI to suggest interpretations of some results but you must declare this use and interpret the results yourself; you may use an AI to suggest how to correct your grammar and spelling but you must declare this use and write the prose yourself.

If markers think that you might have committed an academic offence then they may require you to attend a viva (oral exam) in order to establish the legitimacy of your work.

# Submission Requirements

- A **PDF report** (no more than 8 pages excluding figures, or around 3,000 words) submitted to ELE. You can either directly render to PDF or render to HTML and print this to PDF.

- Your **GitHub repo** must be shared with your supervisor before the deadline

- A completed GenAI statement as above

- The report should explain your approach, show results clearly, and reflect on model strengths/limitations

- All code must run from the root of the repo using `targets::tar_make()`

---

# Timeline and Support

- **Deadline** for summative assessment: 2025-07-18 12 noon

- **Formative feedback**: You may request **up to 1 pull request review a week**, provided you give **1 week’s notice**

- Final work will be marked based on the version present in your GitHub repo on the submission date

---

# Assessment Criteria (Summary)

| **Component** | **Description** |

|---------------------------|-------------------------------------------------------------------------------|

| Supervised classification | Model quality, evaluation, interpretation |

| Regression modelling | Model fit, interpretation, diagnostic checking |

| Unsupervised learning | Dimension reduction + clustering, evaluation, interpretation |

| Reproducibility & tooling | Use of `targets`, `renv`, `testthat`, `git`; passing CI; project organisation |

| Communication & code quality | Report clarity, code modularity, documentation, visualisation, interpretation |

*A full rubric will be provided separately.*

---

# Tips for Success

- Use `tar_visnetwork()` to visualise your workflow

- Document each step in your pipeline with comments or RMarkdown

- Use branches or feature commits in git to experiment safely

- Think about *audience*: the PDF should communicate clearly to a technically informed but non-expert reader

# Grading Criteria

Each student submission will be graded based on the following components. Marks will be allocated across four core areas, with clear descriptors for performance bands.

## 1. Supervised Classification Task (25%)

**Task:** Predict injury severity in pedestrian-involved collisions using features such as weather, lighting, time, age, etc.

| Grade Range | Description |

|-------------|-------------|

| 70–100% | Clear preprocessing, well-justified model selection, strong metrics (e.g., accuracy, AUC), and discussion. Shows understanding of class imbalance, model validation, and error analysis. |

| 60–69% | Reasonable approach with working model. Moderate discussion of features and results. Minor omissions in evaluation or rationale. |

| 50–59% | Minimal preprocessing, limited justification of the model. Basic metrics shown. Code runs, but insight is limited. |

| <50% | Poor or incomplete analysis. Little or no model evaluation. Serious reproducibility or correctness issues. |

## 2. Regression Task (25%)

**Task:** Explore how age and sex affect method of extrication in road traffic collisions.

| Grade Range | Description |

|-------------|-------------|

| 70–100% | Appropriate regression choice (e.g., logistic, multinomial), interpretation of coefficients, diagnostics and residuals well presented. Reproducible and explained. |

| 60–69% | Correct model used, some interpretation of results. Some discussion of limitations. Minor gaps in clarity or diagnostics. |

| 50–59% | Model runs, but limited insight. Weak interpretation. May misuse regression slightly or skip diagnostics. |

| <50% | Incorrect or incomplete model, misinterpretation of results. No meaningful conclusions. |

## 3. Unsupervised Learning & Dimensionality Reduction (25%)

**Task:** Apply PCA/t-SNE/UMAP and clustering (e.g., k-means, hierarchical) to an appropriate dataset.

| Grade Range | Description |

|-------------|-------------|

| 70–100% | Correct method application. Clear choice and interpretation of reduced dimensions. Clustering well explained and evaluated. Excellent visuals. |

| 60–69% | Analysis works, visuals present. Some interpretation or justification lacking depth. Limited cluster evaluation. |

| 50–59% | Some clustering attempted, unclear dimensionality decisions. Weak links to data story. Poor visual explanation. |

| <50% | Incorrect use of techniques or no coherent analysis. |

## 4. Reproducibility, Tools & Workflow (25%)

**Requirements:** Use of `renv`, `targets`, `testthat`, and GitHub repository. Must submit a PDF report and share a GitHub repo.

| Grade Range | Description |

|-------------|-------------|

| 70–100% | Full pipeline with `targets`, environment locked with `renv`, meaningful tests with `testthat`, and regular Git commits. Uses GitHub Actions. Report is polished and fully reproducible. |

| 60–69% | Some tools used. `renv` or `targets` implemented but not all aspects integrated. Minor test coverage. Some Git usage. |

| 50–59% | Script-based approach. Little or no `renv`/`targets`. Code works, but not reproducible. Repo submitted but poorly organised. |

| <50% | No evidence of reproducibility tools. Major workflow or repo issues. Report and repo inconsistent. |
